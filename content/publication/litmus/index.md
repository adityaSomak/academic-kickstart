+++
abstract = ""
abstract_short = ""
authors = ["Anirudh Srinivasan", "Gauri Kholkar", "Rahul Kejriwal", "Tanuja Ganu", "Sandipan Dandapat", "Sunayana Sitaram", "Balakrishnan Santhanam", "Somak Aditya", "Kalika Bali", "Monojit Choudhury"]
date = "2022-02-03"
image_preview = ""
math = true
publication_types = ["1"]
publication = "In AAAI 2022 Demonstrations"
publication_short = "In *AAAI 2022 Demonstrations*"
selected = true
featured = true
title = "LITMUS Predictor: An AI Assistant for Building Reliable, High-Performing and Fair Multilingual NLP Systems"
projects = ["nlp"]
url_pdf = "https://www.microsoft.com/en-us/research/uploads/prod/2022/01/aaai_demo-3.pdf"
url_dataset = ""
url_video = ""


# Optional featured image (relative to `static/img/` folder).
# [header]
# image = ""
# caption = "My caption :smile:"
# focal_point = "center"

[image]
caption = ""
focal_point = "center"
+++

Pre-trained multilingual language models are gaining popularity due to their cross-lingual zero-shot transfer ability, but these models do not perform equally well in all languages. Evaluating task-specific performance of a model in a large number of languages is often a challenge due to lack of labeled data, as is targeting improvements in low performing languages through few-shot learning. We present a tool - LITMUS Predictor - that can make reliable performance projections for a fine-tuned task-specific model in a set of languages without test and training data, and help strategize data labeling efforts to optimize performance and fairness objectives.
